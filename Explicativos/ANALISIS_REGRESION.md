# üìä An√°lisis de la Fase de Regresi√≥n - Pipeline Data Science

## üéØ Objetivo General
La fase de regresi√≥n entrena modelos de machine learning para predecir la cantidad de ventas (valor continuo) bas√°ndose en features hist√≥ricas y caracter√≠sticas de productos/comunas. Se eval√∫an m√∫ltiples algoritmos de regresi√≥n para encontrar el mejor modelo.

---

## üì• Entrada del Pipeline de Regresi√≥n

### Dataset de Entrada: `ventas_preprocesadas`
- **Tipo**: `pandas.ParquetDataset`
- **Ubicaci√≥n**: `data/03_primary/ventas_preprocesadas.parquet`
- **Origen**: Output del pipeline de `data_processing`
- **Columnas**: FECHA, PRODUCTO, COMUNA, CANTIDAD, MES, PRODUCTO_ID, COMUNA_ID, VENTA_MES_ANTERIOR, AUMENTA, VENTA_CLASE

---

## üîÑ Flujo del Pipeline de Regresi√≥n (5 Nodos)

### **NODO 1: `preparar_datos_regresion_node`**
**Funci√≥n**: `preparar_datos_regresion()`

#### ¬øQu√© hace?
- **Prepara los datos** para modelos de regresi√≥n
- **Crea features hist√≥ricas** adicionales (promedios m√≥viles, delta)
- **Define la variable objetivo** como CANTIDAD (valor continuo)
- **Muestrea los datos** si son muy grandes (m√°ximo 10,000 muestras por defecto)

#### Transformaciones espec√≠ficas:

1. **Muestreo** (si `len(df) > max_samples`):
   - Toma una muestra aleatoria de `max_samples` filas
   - Usa `random_state=42` para reproducibilidad
   - **Prop√≥sito**: Reducir tiempo de c√≥mputo

2. **Limpieza b√°sica**:
   - Normaliza nombres de columnas (elimina espacios)
   - Convierte FECHA a datetime
   - Elimina filas con fechas inv√°lidas

3. **Variables base**:
   - `MES`: Mes extra√≠do de la fecha (1-12)
   - `PRODUCTO_ID`: C√≥digo num√©rico del producto
   - `COMUNA_ID`: C√≥digo num√©rico de la comuna

4. **Variables hist√≥ricas agrupadas**:
   - `VENTA_MES_ANTERIOR`: Cantidad vendida el mes anterior (usando `shift(1)`)
   - `PROM_3_MESES`: Promedio m√≥vil de 3 meses
   - `PROM_6_MESES`: Promedio m√≥vil de 6 meses
   - `DELTA_MES`: Cambio porcentual respecto al mes anterior
     - F√≥rmula: `(CANTIDAD - VENTA_MES_ANTERIOR) / VENTA_MES_ANTERIOR`
     - Solo calculado cuando `VENTA_MES_ANTERIOR != 0`

5. **Limpieza final**:
   - Elimina filas con nulos en `VENTA_MES_ANTERIOR`

6. **Separaci√≥n X e y**:
   - **X**: Features num√©ricas (MES, PRODUCTO_ID, COMUNA_ID, VENTA_MES_ANTERIOR, PROM_3_MESES, PROM_6_MESES, DELTA_MES)
   - **y**: Variable objetivo (CANTIDAD - valor continuo)

#### Outputs:
- **`X_reg`**: Features para regresi√≥n (ParquetDataset)
- **`y_reg`**: Variable objetivo (ParquetDataset)

---

### **NODO 2: `pre_proceso_rg_node`**
**Funci√≥n**: `pre_proceso_rg()`

#### ¬øQu√© hace?
- **Ajusta el tama√±o** de X e y a un valor fijo (56884 filas por defecto)
- **Prop√≥sito**: Asegurar consistencia en el tama√±o de los datos

#### ‚ö†Ô∏è Observaci√≥n:
- **Hardcode de 56884 filas**: Esto parece ser un valor espec√≠fico de un dataset anterior
- **Riesgo**: Si los datos tienen menos de 56884 filas, puede causar errores o p√©rdida de datos
- **Recomendaci√≥n**: Deber√≠a ser din√°mico o removerse si no es necesario

#### Transformaciones:
- Trunca X e y a las primeras n_filas filas
- Resetea √≠ndices

#### Outputs:
- **`X_reg_proc`**: Features preprocesadas (ParquetDataset)
- **`y_reg_proc`**: Variable objetivo preprocesada (ParquetDataset)

---

### **NODO 3: `dividir_datos_reg_node`**
**Funci√≥n**: `dividir_datos_reg()`

#### ¬øQu√© hace?
- **Divide los datos** en conjuntos de entrenamiento y prueba
- **Usa train_test_split** de sklearn

#### Par√°metros:
- `test_size`: 0.2 (20% para prueba, 80% para entrenamiento)
- `random_state`: 42 (reproducibilidad)

#### Outputs:
- **`X_train_reg`**: Features de entrenamiento (ParquetDataset)
- **`X_test_reg`**: Features de prueba (ParquetDataset)
- **`y_train_reg`**: Variable objetivo de entrenamiento (ParquetDataset)
- **`y_test_reg`**: Variable objetivo de prueba (ParquetDataset)

---

### **NODO 4: `entrenar_modelos_regresion_node`**
**Funci√≥n**: `entrenar_modelos_regresion_cv()`

#### ¬øQu√© hace?
- **Entrena 5 modelos de regresi√≥n** diferentes
- **Usa GridSearchCV** para optimizar hiperpar√°metros (cuando aplica)
- **Usa validaci√≥n cruzada** (KFold con 5 folds)
- **Guarda los modelos** entrenados en archivos .pkl

#### Modelos entrenados:

1. **LinearRegression**:
   - Modelo lineal b√°sico
   - Sin hiperpar√°metros a optimizar

2. **Ridge**:
   - Regresi√≥n con regularizaci√≥n L2
   - Par√°metros optimizados: `alpha` [0.1, 1.0, 10.0]

3. **Lasso**:
   - Regresi√≥n con regularizaci√≥n L1
   - Par√°metros optimizados: `alpha` [0.01, 0.1, 1.0]

4. **RandomForestRegressor**:
   - Bosque aleatorio para regresi√≥n
   - Par√°metros optimizados: `n_estimators` [50, 100]
   - `random_state`: 42, `n_jobs`: -1

5. **GradientBoostingRegressor**:
   - Boosting con gradiente para regresi√≥n
   - Par√°metros optimizados: `n_estimators` [50, 100]
   - `random_state`: 42

#### Proceso:
- Para cada modelo:
  1. Si tiene par√°metros, crea GridSearchCV con validaci√≥n cruzada (5 folds)
  2. Si no tiene par√°metros, entrena directamente
  3. Selecciona el mejor modelo seg√∫n el score CV (si aplica)
  4. Guarda el mejor modelo en `models_reg/{nombre}.pkl`
  5. Almacena: mejor modelo, mejores par√°metros, score CV

#### Output: `resultados_reg`
- **Tipo**: `pickle.PickleDataset`
- **Ubicaci√≥n**: `data/06_models/resultados_reg.pickle`
- **Contenido**: Diccionario con 5 modelos entrenados, cada uno con:
  - `modelo`: Mejor estimador encontrado
  - `mejor_params`: Mejores hiperpar√°metros
  - `score_cv`: Score promedio de validaci√≥n cruzada (si aplica)

---

### **NODO 5: `evaluar_modelos_regresion_node`**
**Funci√≥n**: `evaluar_modelos_regresion()`

#### ¬øQu√© hace?
- **Eval√∫a cada modelo** en el conjunto de prueba
- **Calcula m√©tricas** de regresi√≥n
- **Compara el rendimiento** de todos los modelos

#### M√©tricas calculadas (para cada modelo):

1. **RMSE (Root Mean Squared Error)**:
   - Ra√≠z cuadrada del error cuadr√°tico medio
   - Mide la desviaci√≥n promedio de las predicciones
   - Rango: 0 a ‚àû (m√°s bajo = mejor)
   - Unidades: Mismas que la variable objetivo

2. **MAE (Mean Absolute Error)**:
   - Error absoluto medio
   - Mide el error promedio en valor absoluto
   - Rango: 0 a ‚àû (m√°s bajo = mejor)
   - Unidades: Mismas que la variable objetivo
   - Menos sensible a outliers que RMSE

3. **R¬≤ (Coefficient of Determination)**:
   - Coeficiente de determinaci√≥n
   - Mide qu√© tan bien el modelo explica la varianza
   - Rango: -‚àû a 1 (m√°s alto = mejor)
   - 1 = predicci√≥n perfecta, 0 = modelo no mejor que la media, <0 = peor que la media

#### Proceso:
- Para cada modelo en `resultados_reg`:
  1. Hace predicciones en `X_test`
  2. Calcula las 3 m√©tricas usando `y_test` y `y_pred`
  3. Almacena las m√©tricas en un diccionario

#### Output: `metricas_reg`
- **Tipo**: `pandas.ParquetDataset`
- **Ubicaci√≥n**: `data/08_reporting/metricas_reg.parquet`
- **Formato**: DataFrame con filas = modelos, columnas = m√©tricas
- **Contenido**:
  ```
  Modelo              | RMSE  | MAE   | R2
  --------------------|-------|-------|-------
  LinearRegression    |  X.XX |  X.XX | 0.XX
  Ridge               |  X.XX |  X.XX | 0.XX
  Lasso               |  X.XX |  X.XX | 0.XX
  RandomForest        |  X.XX |  X.XX | 0.XX
  GradientBoosting    |  X.XX |  X.XX | 0.XX
  ```

---

## üìä Resumen del Pipeline de Regresi√≥n

### Flujo Visual:
```
ventas_preprocesadas
    ‚Üì
[preparar_datos_regresion] ‚Üí X_reg, y_reg
    ‚Üì
[pre_proceso_rg] ‚Üí X_reg_proc, y_reg_proc (ajusta a n_filas filas)
    ‚Üì
[dividir_datos_reg] ‚Üí X_train_reg, X_test_reg, y_train_reg, y_test_reg
    ‚Üì
[entrenar_modelos_regresion_cv] ‚Üí resultados_reg (5 modelos entrenados)
    ‚Üì
[evaluar_modelos_regresion] ‚Üí metricas_reg (DataFrame con m√©tricas)
```

### Features Utilizadas (7 features):
1. `MES`: Mes de la venta (1-12)
2. `PRODUCTO_ID`: C√≥digo num√©rico del producto
3. `COMUNA_ID`: C√≥digo num√©rico de la comuna
4. `VENTA_MES_ANTERIOR`: Cantidad vendida el mes anterior
5. `PROM_3_MESES`: Promedio m√≥vil de 3 meses
6. `PROM_6_MESES`: Promedio m√≥vil de 6 meses
7. `DELTA_MES`: Cambio porcentual respecto al mes anterior

### Variable Objetivo:
- **CANTIDAD**: Valor continuo (n√∫mero de unidades vendidas)
- **Tipo**: Regresi√≥n (predicci√≥n de valores num√©ricos)

### Modelos Evaluados (5):
1. **LinearRegression**: Regresi√≥n lineal (sin regularizaci√≥n)
2. **Ridge**: Regresi√≥n con regularizaci√≥n L2
3. **Lasso**: Regresi√≥n con regularizaci√≥n L1
4. **RandomForestRegressor**: Bosque aleatorio (ensemble)
5. **GradientBoostingRegressor**: Boosting con gradiente (ensemble)

### T√©cnicas Utilizadas:
- **GridSearchCV**: B√∫squeda exhaustiva de hiperpar√°metros
- **KFold**: Validaci√≥n cruzada (5 folds)
- **M√©tricas de regresi√≥n**: RMSE, MAE, R¬≤

---

## ‚ö†Ô∏è Observaciones y Mejoras Potenciales

### Problemas Identificados:

1. **Hardcode de 56884 filas en `pre_proceso_rg`**:
   - **Problema**: Valor fijo que puede no ser apropiado para todos los datasets
   - **Riesgo**: Si hay menos filas, puede causar errores o p√©rdida de datos
   - **Recomendaci√≥n**: Hacer din√°mico o eliminar si no es necesario

2. **Guardado de modelos en ruta relativa**:
   - **Problema**: `joblib.dump(best_model, f"{output_path}/{nombre}.pkl")` usa ruta relativa
   - **Riesgo**: Puede no guardarse en la ubicaci√≥n esperada
   - **Recomendaci√≥n**: Usar el cat√°logo de Kedro para guardar modelos

3. **Muestreo a 10,000 filas**:
   - **Problema**: Puede perder informaci√≥n valiosa
   - **Recomendaci√≥n**: Considerar aumentar o hacer configurable

4. **y_reg como Series**:
   - **Problema**: `y_reg` se retorna como Series, pero el cat√°logo espera DataFrame para Parquet
   - **Recomendaci√≥n**: Convertir a DataFrame antes de retornar

### Mejoras Sugeridas:

1. **Feature engineering adicional**: Podr√≠an agregarse m√°s features relevantes
2. **Escalado de features**: Considerar estandarizar/normalizar features antes de entrenar
3. **M√©tricas adicionales**: MAPE (Mean Absolute Percentage Error), gr√°ficos de residuos
4. **Validaci√≥n de datos**: Verificar que todas las features est√©n presentes

---

## üìù Outputs Finales del Pipeline de Regresi√≥n:

1. **Features y targets**:
   - `X_reg.parquet`: Features preparadas
   - `y_reg.parquet`: Variable objetivo
   - `X_reg_proc.parquet`: Features preprocesadas
   - `y_reg_proc.parquet`: Target preprocesado

2. **Datos divididos**:
   - `X_train_reg.parquet`: Features de entrenamiento
   - `X_test_reg.parquet`: Features de prueba
   - `y_train_reg.parquet`: Target de entrenamiento
   - `y_test_reg.parquet`: Target de prueba

3. **Modelos entrenados**:
   - `resultados_reg.pickle`: Diccionario con 5 modelos entrenados
   - Modelos guardados en `models_reg/` (si se usa ruta relativa)

4. **M√©tricas de evaluaci√≥n**:
   - `metricas_reg.parquet`: DataFrame con m√©tricas de todos los modelos

---

## üéØ Prop√≥sito de la Regresi√≥n:

La regresi√≥n permite:
- **Predecir la cantidad exacta de ventas** bas√°ndose en caracter√≠sticas hist√≥ricas
- **Identificar patrones** que influyen en el volumen de ventas
- **Tomar decisiones** sobre inventario, producci√≥n, o distribuci√≥n basadas en predicciones num√©ricas
- **Comparar modelos** para seleccionar el mejor algoritmo para este problema espec√≠fico
- **Entender relaciones** entre features y la variable objetivo mediante modelos interpretables (Linear, Ridge, Lasso)

