# üìä An√°lisis de la Fase de Clasificaci√≥n - Pipeline Data Science

## üéØ Objetivo General
La fase de clasificaci√≥n entrena modelos de machine learning para predecir la clase de venta (baja/media/alta) bas√°ndose en features hist√≥ricas y caracter√≠sticas de productos/comunas. Se eval√∫an m√∫ltiples algoritmos para encontrar el mejor modelo.

---

## üì• Entrada del Pipeline de Clasificaci√≥n

### Dataset de Entrada: `ventas_preprocesadas`
- **Tipo**: `pandas.ParquetDataset`
- **Ubicaci√≥n**: `data/03_primary/ventas_preprocesadas.parquet`
- **Origen**: Output del pipeline de `data_processing`
- **Columnas**: FECHA, PRODUCTO, COMUNA, CANTIDAD, MES, PRODUCTO_ID, COMUNA_ID, VENTA_MES_ANTERIOR, AUMENTA, VENTA_CLASE

---

## üîÑ Flujo del Pipeline de Clasificaci√≥n (5 Nodos)

### **NODO 1: `preparar_datos_clasificacion_node`**
**Funci√≥n**: `preparar_datos_clasificacion()`

#### ¬øQu√© hace?
- **Prepara los datos** para modelos de clasificaci√≥n
- **Crea features hist√≥ricas** adicionales (promedios m√≥viles, delta)
- **Crea la variable objetivo** (VENTA_CLASE) basada en rangos de cantidad
- **Muestrea los datos** si son muy grandes (m√°ximo 10,000 muestras por defecto)

#### Transformaciones espec√≠ficas:

1. **Muestreo** (si `len(df) > max_samples`):
   - Toma una muestra aleatoria de `max_samples` filas
   - Usa `random_state=42` para reproducibilidad
   - **Prop√≥sito**: Reducir tiempo de c√≥mputo

2. **Limpieza b√°sica**:
   - Normaliza nombres de columnas (elimina espacios)
   - Convierte FECHA a datetime
   - Elimina filas con fechas inv√°lidas

3. **Variables base**:
   - `MES`: Mes extra√≠do de la fecha (1-12)
   - `PRODUCTO_ID`: C√≥digo num√©rico del producto
   - `COMUNA_ID`: C√≥digo num√©rico de la comuna

4. **Variables hist√≥ricas agrupadas**:
   - `VENTA_MES_ANTERIOR`: Cantidad vendida el mes anterior (usando `shift(1)`)
   - `PROM_3_MESES`: Promedio m√≥vil de 3 meses
   - `PROM_6_MESES`: Promedio m√≥vil de 6 meses
   - `DELTA_MES`: Cambio porcentual respecto al mes anterior
     - F√≥rmula: `(CANTIDAD - VENTA_MES_ANTERIOR) / VENTA_MES_ANTERIOR`
     - Solo calculado cuando `VENTA_MES_ANTERIOR != 0`

5. **Variable objetivo (VENTA_CLASE)**:
   - Clasificaci√≥n multiclase basada en rangos de CANTIDAD:
     - **Clase 0 (baja)**: CANTIDAD < 10
     - **Clase 1 (media)**: 10 ‚â§ CANTIDAD < 50
     - **Clase 2 (alta)**: CANTIDAD ‚â• 50
   - Usa `pd.cut()` con bins: `[0, 10, 50, max(CANTIDAD)]`

6. **Limpieza final**:
   - Elimina filas con nulos en `VENTA_MES_ANTERIOR` o `VENTA_CLASE`
   - Convierte todas las features a enteros (int32)
   - Rellena nulos con 0 antes de convertir

7. **Separaci√≥n X e y**:
   - **X**: Features num√©ricas (MES, PRODUCTO_ID, COMUNA_ID, VENTA_MES_ANTERIOR, PROM_3_MESES, PROM_6_MESES, DELTA_MES)
   - **y**: Variable objetivo (VENTA_CLASE codificada como int8: 0, 1, 2)

#### Outputs:
- **`X_clf`**: Features para clasificaci√≥n (ParquetDataset)
- **`y_clf`**: Variable objetivo (ParquetDataset)

---

### **NODO 2: `pre_proceso_clf_node`**
**Funci√≥n**: `pre_proceso_clf()`

#### ¬øQu√© hace?
- **Ajusta el tama√±o** de X e y a un valor fijo (56884 filas)
- **Prop√≥sito**: Asegurar consistencia en el tama√±o de los datos

#### ‚ö†Ô∏è Observaci√≥n:
- **Hardcode de 56884 filas**: Esto parece ser un valor espec√≠fico de un dataset anterior
- **Riesgo**: Si los datos tienen menos de 56884 filas, puede causar errores
- **Recomendaci√≥n**: Deber√≠a ser din√°mico o removerse si no es necesario

#### Transformaciones:
- Trunca X e y a las primeras 56884 filas
- Resetea √≠ndices

#### Outputs:
- **`X_clf_proc`**: Features preprocesadas (ParquetDataset)
- **`y_clf_proc`**: Variable objetivo preprocesada (ParquetDataset)

---

### **NODO 3: `dividir_datos_clf_node`**
**Funci√≥n**: `dividir_datos_clf()`

#### ¬øQu√© hace?
- **Divide los datos** en conjuntos de entrenamiento y prueba
- **Usa train_test_split** de sklearn

#### Par√°metros:
- `test_size`: 0.2 (20% para prueba, 80% para entrenamiento)
- `random_state`: 42 (reproducibilidad)

#### Outputs:
- **`X_train_clf`**: Features de entrenamiento (ParquetDataset)
- **`X_test_clf`**: Features de prueba (ParquetDataset)
- **`y_train_clf`**: Variable objetivo de entrenamiento (ParquetDataset)
- **`y_test_clf`**: Variable objetivo de prueba (ParquetDataset)

---

### **NODO 4: `entrenar_modelos_clasificacion_node`**
**Funci√≥n**: `entrenar_modelos_clasificacion_cv()`

#### ¬øQu√© hace?
- **Entrena 5 modelos de clasificaci√≥n** diferentes
- **Usa GridSearchCV** para optimizar hiperpar√°metros
- **Usa validaci√≥n cruzada** (StratifiedKFold con 5 folds)
- **Guarda los modelos** entrenados en archivos .pkl

#### Modelos entrenados:

1. **LogisticRegression**:
   - Par√°metros optimizados: `C` [0.01, 0.1, 1, 10]
   - `max_iter`: 1000

2. **RandomForestClassifier**:
   - Par√°metros optimizados: `n_estimators` [50, 100, 200]
   - `random_state`: 42

3. **GradientBoostingClassifier**:
   - Par√°metros optimizados: `n_estimators` [50, 100]
   - `random_state`: 42

4. **SVC (Support Vector Classifier)**:
   - Par√°metros optimizados: `C` [0.1, 1, 10]
   - `probability=True` (para obtener probabilidades)

5. **KNeighborsClassifier (KNN)**:
   - Par√°metros optimizados: `n_neighbors` [3, 5, 7]

#### Proceso:
- Para cada modelo:
  1. Crea GridSearchCV con el modelo y par√°metros
  2. Entrena con validaci√≥n cruzada (5 folds estratificados)
  3. Selecciona el mejor modelo seg√∫n el score CV
  4. Guarda el mejor modelo en `models_clf/{nombre}.pkl`
  5. Almacena: mejor modelo, mejores par√°metros, score CV

#### Output: `resultados_clf`
- **Tipo**: `pickle.PickleDataset`
- **Ubicaci√≥n**: `data/06_models/resultados_clf.pickle`
- **Contenido**: Diccionario con 5 modelos entrenados, cada uno con:
  - `modelo`: Mejor estimador encontrado
  - `mejor_params`: Mejores hiperpar√°metros
  - `score_cv`: Score promedio de validaci√≥n cruzada

---

### **NODO 5: `evaluar_modelos_clasificacion_node`**
**Funci√≥n**: `evaluar_modelos_clasificacion()`

#### ¬øQu√© hace?
- **Eval√∫a cada modelo** en el conjunto de prueba
- **Calcula m√©tricas** de clasificaci√≥n multiclase
- **Compara el rendimiento** de todos los modelos

#### M√©tricas calculadas (para cada modelo):

1. **Accuracy (Precisi√≥n)**:
   - Proporci√≥n de predicciones correctas
   - Rango: 0 a 1 (m√°s alto = mejor)

2. **Precision (Precisi√≥n)**:
   - Promedio ponderado de precisi√≥n por clase
   - Mide qu√© tan precisas son las predicciones positivas
   - Rango: 0 a 1 (m√°s alto = mejor)

3. **Recall (Sensibilidad)**:
   - Promedio ponderado de recall por clase
   - Mide qu√© tan bien encuentra las clases positivas
   - Rango: 0 a 1 (m√°s alto = mejor)

4. **F1 Score**:
   - Media arm√≥nica de Precision y Recall
   - Balance entre precisi√≥n y sensibilidad
   - Rango: 0 a 1 (m√°s alto = mejor)

#### Proceso:
- Para cada modelo en `resultados_clf`:
  1. Hace predicciones en `X_test`
  2. Calcula las 4 m√©tricas usando `y_test` y `y_pred`
  3. Almacena las m√©tricas en un diccionario

#### Output: `metricas_clf`
- **Tipo**: `pandas.ParquetDataset`
- **Ubicaci√≥n**: `data/08_reporting/metricas_clf.parquet`
- **Formato**: DataFrame con filas = modelos, columnas = m√©tricas
- **Contenido**:
  ```
  Modelo              | Accuracy | Precision | Recall | F1
  --------------------|----------|-----------|--------|----
  LogisticRegression  |   0.XX   |   0.XX    |  0.XX  | 0.XX
  RandomForest        |   0.XX   |   0.XX    |  0.XX  | 0.XX
  GradientBoosting    |   0.XX   |   0.XX    |  0.XX  | 0.XX
  SVC                 |   0.XX   |   0.XX    |  0.XX  | 0.XX
  KNN                 |   0.XX   |   0.XX    |  0.XX  | 0.XX
  ```

---

## üìä Resumen del Pipeline de Clasificaci√≥n

### Flujo Visual:
```
ventas_preprocesadas
    ‚Üì
[preparar_datos_clasificacion] ‚Üí X_clf, y_clf
    ‚Üì
[pre_proceso_clf] ‚Üí X_clf_proc, y_clf_proc (ajusta a 56884 filas)
    ‚Üì
[dividir_datos_clf] ‚Üí X_train_clf, X_test_clf, y_train_clf, y_test_clf
    ‚Üì
[entrenar_modelos_clasificacion_cv] ‚Üí resultados_clf (5 modelos entrenados)
    ‚Üì
[evaluar_modelos_clasificacion] ‚Üí metricas_clf (DataFrame con m√©tricas)
```

### Features Utilizadas (7 features):
1. `MES`: Mes de la venta (1-12)
2. `PRODUCTO_ID`: C√≥digo num√©rico del producto
3. `COMUNA_ID`: C√≥digo num√©rico de la comuna
4. `VENTA_MES_ANTERIOR`: Cantidad vendida el mes anterior
5. `PROM_3_MESES`: Promedio m√≥vil de 3 meses
6. `PROM_6_MESES`: Promedio m√≥vil de 6 meses
7. `DELTA_MES`: Cambio porcentual respecto al mes anterior

### Variable Objetivo:
- **VENTA_CLASE**: Clasificaci√≥n multiclase (3 clases)
  - **Clase 0 (baja)**: CANTIDAD < 10
  - **Clase 1 (media)**: 10 ‚â§ CANTIDAD < 50
  - **Clase 2 (alta)**: CANTIDAD ‚â• 50

### Modelos Evaluados (5):
1. **LogisticRegression**: Regresi√≥n log√≠stica (lineal)
2. **RandomForest**: Bosque aleatorio (ensemble)
3. **GradientBoosting**: Boosting con gradiente (ensemble)
4. **SVC**: M√°quinas de vectores de soporte (kernel)
5. **KNN**: K-Vecinos m√°s cercanos (basado en instancias)

### T√©cnicas Utilizadas:
- **GridSearchCV**: B√∫squeda exhaustiva de hiperpar√°metros
- **StratifiedKFold**: Validaci√≥n cruzada estratificada (5 folds)
- **M√©tricas multiclase**: Accuracy, Precision, Recall, F1 (weighted average)

---

## ‚ö†Ô∏è Observaciones y Mejoras Potenciales

### Problemas Identificados:

1. **Hardcode de 56884 filas en `pre_proceso_clf`**:
   - **Problema**: Valor fijo que puede no ser apropiado para todos los datasets
   - **Riesgo**: Si hay menos filas, puede causar errores o p√©rdida de datos
   - **Recomendaci√≥n**: Hacer din√°mico o eliminar si no es necesario

2. **Guardado de modelos en ruta relativa**:
   - **Problema**: `joblib.dump(gs.best_estimator_, f"{output_path}/{nombre}.pkl")` usa ruta relativa
   - **Riesgo**: Puede no guardarse en la ubicaci√≥n esperada
   - **Recomendaci√≥n**: Usar el cat√°logo de Kedro para guardar modelos

3. **Muestreo a 10,000 filas**:
   - **Problema**: Puede perder informaci√≥n valiosa
   - **Recomendaci√≥n**: Considerar aumentar o hacer configurable

### Mejoras Sugeridas:

1. **Balanceo de clases**: Las clases pueden estar desbalanceadas (baja tiene m√°s registros)
2. **Feature engineering adicional**: Podr√≠an agregarse m√°s features relevantes
3. **M√©tricas adicionales**: Matriz de confusi√≥n, reporte de clasificaci√≥n por clase
4. **Validaci√≥n de datos**: Verificar que todas las features est√©n presentes

---

## üìù Outputs Finales del Pipeline de Clasificaci√≥n:

1. **Features y targets**:
   - `X_clf.parquet`: Features preparadas
   - `y_clf.parquet`: Variable objetivo
   - `X_clf_proc.parquet`: Features preprocesadas
   - `y_clf_proc.parquet`: Target preprocesado

2. **Datos divididos**:
   - `X_train_clf.parquet`: Features de entrenamiento
   - `X_test_clf.parquet`: Features de prueba
   - `y_train_clf.parquet`: Target de entrenamiento
   - `y_test_clf.parquet`: Target de prueba

3. **Modelos entrenados**:
   - `resultados_clf.pickle`: Diccionario con 5 modelos entrenados
   - Modelos guardados en `models_clf/` (si se usa ruta relativa)

4. **M√©tricas de evaluaci√≥n**:
   - `metricas_clf.parquet`: DataFrame con m√©tricas de todos los modelos

---

## üéØ Prop√≥sito de la Clasificaci√≥n:

La clasificaci√≥n permite:
- **Predecir el nivel de ventas** (baja/media/alta) bas√°ndose en caracter√≠sticas hist√≥ricas
- **Identificar patrones** que influyen en el volumen de ventas
- **Tomar decisiones** sobre inventario, promociones, o distribuci√≥n basadas en predicciones
- **Comparar modelos** para seleccionar el mejor algoritmo para este problema espec√≠fico

