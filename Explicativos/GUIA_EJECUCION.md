# ğŸ“š GuÃ­a de EjecuciÃ³n del Proyecto Kedro

Esta guÃ­a te mostrarÃ¡ paso a paso cÃ³mo ejecutar el proyecto completo desde la terminal.

---

## ğŸ“‹ Tabla de Contenidos

1. [Requisitos Previos](#requisitos-previos)
2. [ConfiguraciÃ³n Inicial](#configuraciÃ³n-inicial)
3. [EjecuciÃ³n de Pipelines](#ejecuciÃ³n-de-pipelines)
4. [VisualizaciÃ³n de Resultados](#visualizaciÃ³n-de-resultados)
5. [Comandos Ãštiles](#comandos-Ãºtiles)

---

## ğŸ”§ Requisitos Previos

- Python 3.8 o superior
- Git (opcional, para clonar el repositorio)
- Terminal (PowerShell, CMD, o Git Bash en Windows)

---

## ğŸš€ ConfiguraciÃ³n Inicial

### Paso 1: Navegar al Directorio del Proyecto

```powershell
cd "C:\Users\raulr\OneDrive\Escritorio\Proyecto definitivo\proyecto-kedro"
cd "C:Ruta de tu archivo"
```

### Paso 2: Crear y Activar el Entorno Virtual

**Crear el entorno virtual:**
```powershell
python -m venv venv
```

**Activar el entorno virtual:**

En PowerShell:
```powershell
.\venv\Scripts\Activate.ps1
```

En CMD:
```cmd
venv\Scripts\activate.bat
```

**Verificar que el entorno estÃ¡ activo:**
```powershell
python --version
```

DeberÃ­as ver la versiÃ³n de Python y el prefijo `(venv)` en tu terminal.

### Paso 3: Instalar Dependencias

```powershell
pip install --upgrade pip
pip install -r requirements.txt
```

**Verificar instalaciÃ³n de Kedro:**
```powershell
kedro --version
```

---

## ğŸ”„ EjecuciÃ³n de Pipelines

### OpciÃ³n A: Ejecutar Todo el Proyecto Completo

Este comando ejecuta todos los pipelines en orden:
- `data_processing`
- `data_science` (clustering, clasificaciÃ³n, regresiÃ³n)
- `reporting`

```powershell
kedro run
```

### OpciÃ³n B: Ejecutar Pipelines Individuales

#### 1. Pipeline de Data Processing

```powershell
kedro run --pipeline data_processing
```

**QuÃ© hace:**
- Limpia y normaliza los datos de `matriz-venta.csv`
- Crea features nuevas (MES, PRODUCTO_ID, COMUNA_ID, VENTA_MES_ANTERIOR, AUMENTA, VENTA_CLASE)
- Genera el dataset `ventas_preprocesadas`

#### 2. Pipeline de Clustering

```powershell
kedro run --pipeline data_science --node prepare_clustering_data_node
kedro run --pipeline data_science --node scale_features_node
kedro run --pipeline data_science --node train_kmeans_node
kedro run --pipeline data_science --node train_dbscan_node
kedro run --pipeline data_science --node train_agglomerative_node
kedro run --pipeline data_science --node train_gmm_node
```

**O ejecutar todo el clustering de una vez:**
```powershell
kedro run --pipeline data_science --tags clustering
```

**QuÃ© hace:**
- Prepara datos para clustering
- Estandariza features
- Entrena 4 algoritmos: K-Means, DBSCAN, Agglomerative, GMM
- EvalÃºa y guarda mÃ©tricas de cada algoritmo

#### 3. Pipeline de ClasificaciÃ³n

```powershell
kedro run --pipeline data_science --tags classification
```

**QuÃ© hace:**
- Prepara datos para clasificaciÃ³n (predecir VENTA_CLASE)
- Divide en entrenamiento y prueba
- Entrena 5 modelos: LogisticRegression, RandomForest, GradientBoosting, SVC, KNN
- EvalÃºa y guarda mÃ©tricas

#### 4. Pipeline de RegresiÃ³n

```powershell
kedro run --pipeline data_science --tags regression
```

**QuÃ© hace:**
- Prepara datos para regresiÃ³n (predecir CANTIDAD)
- Divide en entrenamiento y prueba
- Entrena 5 modelos: LinearRegression, Ridge, Lasso, RandomForest, GradientBoosting
- EvalÃºa y guarda mÃ©tricas

#### 5. Pipeline de Reporting

```powershell
kedro run --pipeline reporting
```

**QuÃ© hace:**
- Genera reportes estructurados de todos los pipelines
- Crea archivos pickle con anÃ¡lisis completos:
  - `analisis_pipeline_data_processing.pickle`
  - `analisis_pipeline_clustering.pickle`
  - `analisis_pipeline_clasificacion.pickle`
  - `analisis_pipeline_regresion.pickle`

---

## ğŸ“Š VisualizaciÃ³n de Resultados

### OpciÃ³n 1: Ejecutar Notebooks en Jupyter

#### Paso 1: Iniciar Jupyter Notebook

```powershell
cd "C:\Users\raulr\OneDrive\Escritorio\Proyecto definitivo\proyecto-kedro"
.\venv\Scripts\python.exe -m jupyter notebook notebooks
```

O usar el script creado:
```powershell
.\iniciar_jupyter.bat
```

#### Paso 2: Abrir y Ejecutar los Notebooks

1. Se abrirÃ¡ tu navegador con la interfaz de Jupyter
2. Selecciona el kernel: **"Python 3 (ipykernel)"**
3. Ejecuta los notebooks en este orden:
   - `01_Reporte_Data_Processing.ipynb`
   - `02_Reporte_Clustering.ipynb`
   - `03_Reporte_Clasificacion.ipynb`
   - `04_Reporte_Regresion.ipynb`
   - `05_Resumen_General.ipynb`

**Para ejecutar cada celda:**
- `Shift + Enter`: Ejecutar celda y avanzar
- `Ctrl + Enter`: Ejecutar celda sin avanzar
- `Alt + Enter`: Ejecutar celda y crear nueva

### OpciÃ³n 2: Ver Datos Directamente desde Python

Puedes cargar y explorar los datos directamente:

```powershell
python
```

```python
from pathlib import Path
from kedro.framework.startup import bootstrap_project
from kedro.framework.session import KedroSession
import pandas as pd

# Inicializar proyecto
project_path = Path.cwd()
bootstrap_project(project_path)
session = KedroSession.create(project_path=project_path)
catalog = session.load_context().catalog

# Cargar datos
ventas = catalog.load('ventas_preprocesadas')
print(ventas.head())
print(ventas.shape)

# Cargar reportes
analisis_dp = catalog.load('analisis_pipeline_data_processing')
print(analisis_dp.keys())

session.close()
```

---

## ğŸ› ï¸ Comandos Ãštiles

### Ver Estructura del Proyecto

```powershell
tree /F /A
```

### Ver CatÃ¡logo de Datos Disponibles

```powershell
kedro catalog list
```

### Ver InformaciÃ³n de un Dataset EspecÃ­fico

```powershell
kedro catalog describe ventas_preprocesadas
```

### Limpiar CachÃ© de Kedro

Si encuentras problemas con datos desactualizados:

```powershell
kedro catalog clear
```

### Ver ParÃ¡metros del Proyecto

```powershell
kedro pipeline list
```

### Ejecutar un Nodo EspecÃ­fico

```powershell
kedro run --node limpiar_productos_node
```

### Ver Logs Detallados

```powershell
kedro run --verbose
```

### Verificar InstalaciÃ³n de Dependencias

```powershell
pip list
```

### Actualizar Dependencias

```powershell
pip install --upgrade -r requirements.txt
```

---

## ğŸ“ Estructura de Archivos Generados

DespuÃ©s de ejecutar los pipelines, encontrarÃ¡s:

```
proyecto-kedro/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 01_raw/
â”‚   â”‚   â””â”€â”€ matriz-venta.csv
â”‚   â”œâ”€â”€ 02_intermediate/
â”‚   â”‚   â”œâ”€â”€ productos_limpios.parquet
â”‚   â”‚   â”œâ”€â”€ productos_con_peso.parquet
â”‚   â”‚   â”œâ”€â”€ productos_normalizados.parquet
â”‚   â”‚   â””â”€â”€ datos_normalizados.parquet
â”‚   â”œâ”€â”€ 03_primary/
â”‚   â”‚   â””â”€â”€ ventas_preprocesadas.parquet
â”‚   â”œâ”€â”€ 04_feature/
â”‚   â”‚   â”œâ”€â”€ X_clf.parquet
â”‚   â”‚   â”œâ”€â”€ X_reg.parquet
â”‚   â”‚   â”œâ”€â”€ X_clustering.parquet
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ 05_model_input/
â”‚   â”‚   â”œâ”€â”€ X_train_clf.parquet
â”‚   â”‚   â”œâ”€â”€ X_test_clf.parquet
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ 06_models/
â”‚   â”‚   â”œâ”€â”€ modelo_kmeans.pickle
â”‚   â”‚   â”œâ”€â”€ modelo_dbscan.pickle
â”‚   â”‚   â”œâ”€â”€ resultados_clf.pickle
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ 07_model_output/
â”‚   â”‚   â”œâ”€â”€ metricas_clf.parquet
â”‚   â”‚   â”œâ”€â”€ metricas_reg.parquet
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ 08_reporting/
â”‚       â”œâ”€â”€ analisis_pipeline_data_processing.pickle
â”‚       â”œâ”€â”€ analisis_pipeline_clustering.pickle
â”‚       â”œâ”€â”€ analisis_pipeline_clasificacion.pickle
â”‚       â””â”€â”€ analisis_pipeline_regresion.pickle
â””â”€â”€ notebooks/
    â”œâ”€â”€ 01_Reporte_Data_Processing.ipynb
    â”œâ”€â”€ 02_Reporte_Clustering.ipynb
    â”œâ”€â”€ 03_Reporte_Clasificacion.ipynb
    â”œâ”€â”€ 04_Reporte_Regresion.ipynb
    â””â”€â”€ 05_Resumen_General.ipynb
```

---

## ğŸ” VerificaciÃ³n de EjecuciÃ³n Exitosa

### Verificar que los Pipelines se Ejecutaron Correctamente

```powershell
# Verificar que existen los archivos de reporte
Test-Path "data\08_reporting\analisis_pipeline_data_processing.pickle"
Test-Path "data\08_reporting\analisis_pipeline_clustering.pickle"
Test-Path "data\08_reporting\analisis_pipeline_clasificacion.pickle"
Test-Path "data\08_reporting\analisis_pipeline_regresion.pickle"
```

Todos deberÃ­an retornar `True`.

### Verificar Modelos Entrenados

```powershell
# Verificar modelos de clustering
Test-Path "data\06_models\modelo_kmeans.pickle"
Test-Path "data\06_models\modelo_dbscan.pickle"
Test-Path "data\06_models\modelo_agglomerative.pickle"
Test-Path "data\06_models\modelo_gmm.pickle"

# Verificar resultados de clasificaciÃ³n y regresiÃ³n
Test-Path "data\06_models\resultados_clf.pickle"
Test-Path "data\06_models\resultados_reg.pickle"
```

---

## âš ï¸ SoluciÃ³n de Problemas Comunes

### Problema 1: "No module named 'kedro'"

**SoluciÃ³n:**
```powershell
pip install kedro
```

### Problema 2: "Dataset not found in catalog"

**SoluciÃ³n:**
```powershell
kedro catalog clear
kedro run
```

### Problema 3: "Permission denied" al guardar archivos

**SoluciÃ³n:**
- Cierra cualquier programa que pueda estar usando los archivos
- Ejecuta PowerShell como administrador
- O simplemente vuelve a ejecutar el pipeline

### Problema 4: Error al ejecutar notebooks

**SoluciÃ³n:**
1. Verifica que el kernel sea "Python 3 (ipykernel)"
2. AsegÃºrate de que el entorno virtual estÃ© activo
3. Reinstala jupyter si es necesario:
   ```powershell
   pip install jupyter notebook
   ```

### Problema 5: Errores de importaciÃ³n en notebooks

**SoluciÃ³n:**
Verifica que el path del proyecto sea correcto. En los notebooks, el cÃ³digo usa:
```python
project_path = Path.cwd().parent  # Subir un nivel desde notebooks/
```

Si ejecutas desde la raÃ­z del proyecto, cambia a:
```python
project_path = Path.cwd()
```

---

## ğŸ“ Flujo de Trabajo Recomendado

### Primera EjecuciÃ³n Completa

1. **Activar entorno virtual:**
   ```powershell
   .\venv\Scripts\Activate.ps1
   ```

2. **Ejecutar todo el proyecto:**
   ```powershell
   kedro run
   ```

3. **Verificar que todo se ejecutÃ³:**
   ```powershell
   kedro catalog list
   ```

4. **Abrir Jupyter para visualizar:**
   ```powershell
   .\venv\Scripts\python.exe -m jupyter notebook notebooks
   ```

### Ejecuciones Posteriores

Si solo quieres actualizar un pipeline especÃ­fico:

```powershell
# Solo actualizar data processing
kedro run --pipeline data_processing

# Solo actualizar clustering
kedro run --pipeline data_science --tags clustering

# Solo actualizar reportes
kedro run --pipeline reporting
```

---

## ğŸ¯ Resumen de Comandos Esenciales

```powershell
# 1. Activar entorno
.\venv\Scripts\Activate.ps1

# 2. Ejecutar proyecto completo
kedro run

# 3. Abrir Jupyter
.\venv\Scripts\python.exe -m jupyter notebook notebooks

# 4. Ver catÃ¡logo
kedro catalog list

# 5. Limpiar cachÃ© (si hay problemas)
kedro catalog clear
```

---

## âœ… Checklist de VerificaciÃ³n

Antes de considerar el proyecto completamente ejecutado, verifica:

- [ ] Entorno virtual creado y activado
- [ ] Todas las dependencias instaladas
- [ ] Pipeline `data_processing` ejecutado exitosamente
- [ ] Pipeline `data_science` (clustering) ejecutado exitosamente
- [ ] Pipeline `data_science` (clasificaciÃ³n) ejecutado exitosamente
- [ ] Pipeline `data_science` (regresiÃ³n) ejecutado exitosamente
- [ ] Pipeline `reporting` ejecutado exitosamente
- [ ] Todos los archivos de reporte generados en `data/08_reporting/`
- [ ] Notebooks ejecutados y visualizaciones generadas

---

## ğŸ“ Notas Adicionales

- **Tiempo de ejecuciÃ³n:** El proyecto completo tarda aproximadamente 1-2 minutos
- **Espacio en disco:** AsegÃºrate de tener al menos 500 MB libres
- **Memoria:** El proyecto usa muestreo automÃ¡tico para datasets grandes (mÃ¡ximo 10,000 muestras)

---

Â¡Listo! Con esta guÃ­a podrÃ¡s ejecutar el proyecto completo desde la terminal. ğŸš€

