# üê≥ Gu√≠a de Docker y Airflow para el Proyecto Kedro

Esta gu√≠a explica c√≥mo usar Docker y Airflow para orquestar los pipelines de Kedro.

---

## üìã Requisitos Previos

- Docker Desktop instalado y ejecut√°ndose
- Docker Compose (incluido en Docker Desktop)
- Al menos 4GB de RAM disponible
- Al menos 10GB de espacio en disco

---

## üöÄ Inicio R√°pido

### 1. Configurar Variables de Entorno

Crea un archivo `.env` en la ra√≠z del proyecto (ya est√° creado) o ajusta las variables seg√∫n necesites:

```bash
AIRFLOW_UID=50000
_AIRFLOW_WWW_USER_USERNAME=airflow
_AIRFLOW_WWW_USER_PASSWORD=airflow
```

### 2. Construir las Im√°genes Docker

```powershell
docker-compose build
```

Este comando construye la imagen de Airflow con todas las dependencias de Kedro.

### 3. Inicializar Airflow

```powershell
docker-compose up airflow-init
```

Esto inicializa la base de datos de Airflow y crea el usuario administrador.

### 4. Iniciar los Servicios

```powershell
docker-compose up -d
```

Esto inicia:
- **PostgreSQL**: Base de datos para Airflow
- **Airflow Webserver**: Interfaz web en http://localhost:8080
- **Airflow Scheduler**: Planificador de tareas

### 5. Acceder a la Interfaz de Airflow

Abre tu navegador y ve a:
```
http://localhost:8080
```

**Credenciales:**
- Usuario: `airflow`
- Contrase√±a: `airflow`

---

## üìä DAGs Disponibles

Una vez que Airflow est√© ejecut√°ndose, ver√°s los siguientes DAGs:

### 1. `kedro_data_processing`
- **Descripci√≥n**: Ejecuta el pipeline de procesamiento de datos
- **Frecuencia**: Diaria
- **Tareas**: 
  - `run_data_processing_pipeline`: Ejecuta el pipeline
  - `verify_data_processing_output`: Verifica que se generaron los outputs

### 2. `kedro_data_science`
- **Descripci√≥n**: Ejecuta pipelines de ML (Clustering, Clasificaci√≥n, Regresi√≥n)
- **Frecuencia**: Diaria
- **Tareas**:
  - `clustering_tasks`: Grupo de tareas de clustering
  - `classification_tasks`: Grupo de tareas de clasificaci√≥n
  - `regression_tasks`: Grupo de tareas de regresi√≥n

### 3. `kedro_reporting`
- **Descripci√≥n**: Genera reportes de todos los pipelines
- **Frecuencia**: Diaria
- **Tareas**:
  - `run_reporting_pipeline`: Ejecuta el pipeline de reporting
  - `verify_reporting_output`: Verifica que se generaron los reportes

### 4. `kedro_master_pipeline`
- **Descripci√≥n**: DAG maestro que orquesta todos los pipelines en orden
- **Frecuencia**: Diaria
- **Flujo**: Data Processing ‚Üí Data Science ‚Üí Reporting

---

## üõ†Ô∏è Comandos √ötiles

### Ver Logs de los Servicios

```powershell
# Ver todos los logs
docker-compose logs

# Ver logs de un servicio espec√≠fico
docker-compose logs airflow-scheduler
docker-compose logs airflow-webserver

# Seguir logs en tiempo real
docker-compose logs -f airflow-scheduler
```

### Detener los Servicios

```powershell
docker-compose down
```

### Detener y Eliminar Vol√∫menes (‚ö†Ô∏è Elimina datos)

```powershell
docker-compose down -v
```

### Reiniciar un Servicio Espec√≠fico

```powershell
docker-compose restart airflow-scheduler
```

### Ejecutar Comandos en el Contenedor

```powershell
# Ejecutar un comando de Kedro
docker-compose exec airflow-webserver kedro run --pipeline data_processing

# Abrir una shell en el contenedor
docker-compose exec airflow-webserver bash
```

### Ver Estado de los Contenedores

```powershell
docker-compose ps
```

---

## üìÅ Estructura de Directorios

```
proyecto-kedro/
‚îú‚îÄ‚îÄ dags/                          # DAGs de Airflow
‚îÇ   ‚îú‚îÄ‚îÄ kedro_data_processing_dag.py
‚îÇ   ‚îú‚îÄ‚îÄ kedro_data_science_dag.py
‚îÇ   ‚îú‚îÄ‚îÄ kedro_reporting_dag.py
‚îÇ   ‚îî‚îÄ‚îÄ kedro_master_dag.py
‚îú‚îÄ‚îÄ logs/                          # Logs de Airflow y Kedro
‚îÇ   ‚îú‚îÄ‚îÄ airflow.log
‚îÇ   ‚îú‚îÄ‚îÄ kedro.log
‚îÇ   ‚îî‚îÄ‚îÄ dag_*.log
‚îú‚îÄ‚îÄ plugins/                       # Plugins de Airflow
‚îú‚îÄ‚îÄ Dockerfile.airflow             # Imagen de Airflow
‚îú‚îÄ‚îÄ docker-compose.yml             # Configuraci√≥n de servicios
‚îú‚îÄ‚îÄ .env                          # Variables de entorno
‚îî‚îÄ‚îÄ airflow_logging_config.py     # Configuraci√≥n de logging
```

---

## üîç Verificaci√≥n de Logs

### Logs de Airflow

Los logs se encuentran en:
- **Dentro del contenedor**: `/opt/airflow/logs/`
- **En tu m√°quina**: `./logs/`

### Ver Logs de un DAG Espec√≠fico

1. Ve a la interfaz de Airflow (http://localhost:8080)
2. Selecciona el DAG
3. Haz clic en "Graph View"
4. Selecciona una tarea
5. Haz clic en "Log"

### Ver Logs desde la Terminal

```powershell
# Ver logs de Airflow
Get-Content logs\airflow.log -Tail 50

# Ver logs de Kedro
Get-Content logs\kedro.log -Tail 50

# Ver logs de un DAG espec√≠fico
Get-Content logs\dag_kedro_data_processing.log -Tail 50
```

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Cambiar Frecuencia de Ejecuci√≥n

Edita el archivo del DAG (ej: `dags/kedro_data_processing_dag.py`) y modifica:

```python
schedule_interval=timedelta(hours=6),  # Cada 6 horas
# o
schedule_interval='0 0 * * *',  # Diario a medianoche (cron)
```

### Agregar Notificaciones por Email

En `docker-compose.yml`, agrega configuraci√≥n SMTP:

```yaml
environment:
  AIRFLOW__SMTP__SMTP_HOST: smtp.gmail.com
  AIRFLOW__SMTP__SMTP_STARTTLS: 'true'
  AIRFLOW__SMTP__SMTP_SSL: 'false'
  AIRFLOW__SMTP__SMTP_USER: tu_email@gmail.com
  AIRFLOW__SMTP__SMTP_PASSWORD: tu_contrase√±a
  AIRFLOW__SMTP__SMTP_PORT: 587
  AIRFLOW__SMTP__SMTP_MAIL_FROM: tu_email@gmail.com
```

### Ajustar Recursos

En `docker-compose.yml`, puedes agregar l√≠mites de recursos:

```yaml
services:
  airflow-scheduler:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
```

---

## üêõ Soluci√≥n de Problemas

### Problema: "Port 8080 is already in use"

**Soluci√≥n**: Cambia el puerto en `docker-compose.yml`:
```yaml
ports:
  - "8081:8080"  # Cambiar 8080 por 8081
```

### Problema: "Permission denied" en logs

**Soluci√≥n**: Ajusta permisos:
```powershell
# En Windows, aseg√∫rate de que el directorio logs existe y tiene permisos
New-Item -ItemType Directory -Force -Path logs
```

### Problema: DAGs no aparecen en la interfaz

**Soluci√≥n**:
1. Verifica que los archivos est√°n en `dags/`
2. Revisa los logs del scheduler: `docker-compose logs airflow-scheduler`
3. Reinicia el scheduler: `docker-compose restart airflow-scheduler`

### Problema: Error al ejecutar pipelines de Kedro

**Soluci√≥n**:
1. Verifica que el proyecto Kedro est√° correctamente copiado al contenedor
2. Ejecuta manualmente: `docker-compose exec airflow-webserver kedro run`
3. Revisa los logs: `docker-compose logs airflow-scheduler`

---

## üìù Notas Importantes

- **Persistencia de Datos**: Los datos se guardan en vol√∫menes Docker. Si eliminas los vol√∫menes (`docker-compose down -v`), perder√°s los datos.
- **Logs**: Los logs se rotan autom√°ticamente (m√°ximo 10MB por archivo, 5 backups).
- **Rendimiento**: El primer build puede tardar varios minutos. Las ejecuciones posteriores ser√°n m√°s r√°pidas.
- **Recursos**: Aseg√∫rate de tener suficientes recursos asignados a Docker Desktop (m√≠nimo 4GB RAM, 2 CPUs).

---

## ‚úÖ Checklist de Verificaci√≥n

- [ ] Docker Desktop instalado y ejecut√°ndose
- [ ] Imagen construida exitosamente (`docker-compose build`)
- [ ] Airflow inicializado (`docker-compose up airflow-init`)
- [ ] Servicios ejecut√°ndose (`docker-compose ps`)
- [ ] Interfaz web accesible (http://localhost:8080)
- [ ] DAGs visibles en la interfaz
- [ ] Logs gener√°ndose correctamente

---

¬°Listo! Con esta configuraci√≥n podr√°s orquestar todos tus pipelines de Kedro usando Airflow. üöÄ

